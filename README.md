# ğŸ§ Personal Audiobook Studio

**Turn any PDF into an audiobook in *your own voice*.**  
OCR âœ Text Extraction âœ Chunking âœ **Deepgram TTS** âœ **OpenVoice** voice conversion âœ MP3 in a minimal **Gradio** UI.

> Live Demo : [https://huggingface.co/spaces/your-username/personal-audiobook-studio  ](https://huggingface.co/spaces/ZainabEman/Personal_Audiobook_Studio/tree/main)
> Blog : [https://medium.com/@your-handle/personal-audiobook-studio](https://medium.com/@zainabeman976/personal-audiobook-studio-turn-any-pdf-into-an-audiobook-in-your-own-voice-745ce97ac805)

---

<img width="1115" height="647" alt="Image" src="https://github.com/user-attachments/assets/fd997357-0809-4417-b083-290da3df1cb7" />

## âœ¨ Features
- Upload **PDF** (supports scanned & digital) with automatic **OCR** (ocrmypdf + Tesseract)
- Clean & **chunk** text (~800â€“1800 chars) for stable TTS
- **Deepgram TTS** narration âœ **OpenVoice** cloning to your voice (15â€“45s sample)
- **Pydub + FFmpeg** merge to a single MP3
- Minimal **dark** Gradio UI with logs & error messages

---

## ğŸ§° Tech Stack
- **UI**: Gradio
- **Text/OCR**: PyMuPDF, OCRmyPDF, Tesseract
- **Audio**: Deepgram TTS API, OpenVoice CLI, Pydub, FFmpeg
- **Deploy**: Hugging Face Spaces (`requirements.txt`, `packages.txt`)


<img width="1536" height="1024" alt="Image" src="https://github.com/user-attachments/assets/ea999eab-2b64-425b-845c-22b3248aef1f" />
---


# ğŸ“– AI Agent Assignment Phase02 â€“ PDF to Speech & Voice Cloning (Colab)

## âœ… What This Project Does
In this part of the assignment, we created an **AI Agent** that can:
1. **Read a PDF aloud** â€“ Extract text from a PDF and convert it into natural-sounding speech.  
2. **Transcribe audio** â€“ Use Whisper to turn audio recordings into text.  
3. **Do text-to-speech (TTS)** â€“ Convert any input text into speech (WAV output).  
4. **Do speech-to-speech conversion** â€“ Use OpenVoice to clone voices (take speech from one speaker and generate it in another speakerâ€™s voice).  
5. **Run as an AI agent** â€“ The tools are combined into one assistant using LangChain / LangGraph, so the AI can decide which tool to use based on instructions.

---

## ğŸ› ï¸ Tools & Libraries Used
- **LangChain / LangGraph** â€“ For building the agent that coordinates the tools.  
- **Google Gemini API** â€“ As the large language model (LLM) to drive reasoning.  
- **Whisper** â€“ For speech-to-text transcription.  
- **edge-tts** â€“ For neural text-to-speech.  
- **OpenVoice** â€“ For voice cloning (speech-to-speech).  
- **PyPDF2** â€“ For PDF text extraction.  

---

## âš¡ Problems We Faced & How We Solved Them
1. **Dependency conflicts on Colab**  
   - Torch, Whisper, LangChain, and other packages had version mismatches.  
   - âœ… Solved by carefully pinning versions (Torch 2.3.1, LangChain 0.2.14, etc.).  

2. **Missing CUDA/cuDNN libraries**  
   - Torch complained about `libcudnn.so.8` not found.  
   - âœ… Solved by installing CUDA toolkit and cuDNN manually in Colab.  

3. **OpenVoice import issues**  
   - The repo doesnâ€™t expose `infer` directly.  
   - âœ… Solved by switching to subprocess calls to run the official inference script.  

4. **LangChain agent deprecation warning**  
   - `initialize_agent` is being replaced by LangGraph.  
   - âœ… Solved by installing `langgraph` and supporting both (fallback if needed).  

5. **Gemini API errors (â€œcontents is not specifiedâ€)**  
   - Wrong input format was sent to Gemini.  
   - âœ… Solved by passing `{"messages": [("user", instruction)]}` instead of just `{"input": ...}`.  

6. **Hugging Face / OpenVoice checkpoint download**  
   - Needed to manage `huggingface_hub` versions.  
   - âœ… Solved by installing specific versions and allowing checkpoint download without auth token (public).  

---

## ğŸš€ How to Use (Colab Workflow)
1. Run **Cell 1** â†’ Install dependencies.  
2. Run **Cell 2** â†’ (Optional) Install OpenVoice.  
3. Run **Cell 3** â†’ Add your Gemini API key.  
4. Run **Cell 4** â†’ Initialize OpenVoice.  
5. Run **Cell 5** â†’ Build the AI Agent (LangGraph or fallback).  
6. Run **Cell 6** â†’ Give an instruction (e.g., *â€œRead my PDF in a natural voice and give me the WAV pathâ€*).  

---

## ğŸŒŸ Outcome
- We successfully built a **multi-tool AI agent** that can handle **PDF reading, TTS, audio transcription, and voice cloning**.  
- Even though we hit many dependency and compatibility issues, we fixed them step by step.  
- The final system works inside **Google Colab** without needing Streamlit or extra UI.
