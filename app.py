# -*- coding: utf-8 -*-
"""Assignment01_f22-3738.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ik0yG536wuAJShsWIYuEExaSZNn4zIBt
"""

from pathlib import Path

# === ‚úÖ FINAL WORKING GRADIO APP WITH LOGS, LIMITS, AND SAFETY ===

# === Install dependencies ===
!apt-get -y update && apt-get -y install tesseract-ocr ocrmypdf ghostscript poppler-utils ffmpeg
!pip install gradio PyMuPDF pydub regex requests python-dotenv openvoice-cli --quiet

# === Imports ===
import gradio as gr
import os, subprocess, json, shutil, re, requests
from pathlib import Path
from pydub import AudioSegment
import fitz  # PyMuPDF
from dotenv import load_dotenv

load_dotenv()

# === Setup Directories and API ===
BASE = Path("/content")
IN_DIR = BASE / "inputs"; IN_DIR.mkdir(parents=True, exist_ok=True)
OUT_DIR = BASE / "outputs"; OUT_DIR.mkdir(parents=True, exist_ok=True)
AUDIO_DIR = OUT_DIR / "audio_chunks"; AUDIO_DIR.mkdir(parents=True, exist_ok=True)
META_DIR = OUT_DIR / "meta"; META_DIR.mkdir(parents=True, exist_ok=True)

DEEPGRAM_API_KEY = os.getenv("DEEPGRAM_API_KEY") or "96981cd7febf41243f654ec217c37af9599c8c8a"
DG_MODEL = "aura-2-thalia-en"

# === Utilities ===
def is_scanned_pdf(pdf_path, sample_pages=5):
    doc = fitz.open(pdf_path)
    has_text = sum(1 for i in range(min(sample_pages, len(doc))) if doc.load_page(i).get_text().strip())
    return has_text == 0

def ocr_to_searchable_pdf(src, dst):
    subprocess.run(f'ocrmypdf --force-ocr --skip-text --output-type pdf "{src}" "{dst}"', shell=True, check=True)

def extract_text(pdf_path):
    doc = fitz.open(pdf_path)
    return "\\n".join([doc.load_page(i).get_text("text") for i in range(len(doc))])

def clean_text(t: str) -> str:
    t = re.sub(r'(\\w)-\\s*\\n\\s*(\\w)', r'\\1\\2', t)
    t = re.sub(r'[ \\t]*\\n[ \\t]*', ' ', t)
    return re.sub(r'\\s+', ' ', t).strip()

def chunk_text(text: str, target_min=800, target_max=1800):
    parts = re.split(r'([.!?])\\s+', text)
    sents = [parts[i] + (parts[i+1] if i+1 < len(parts) else '') for i in range(0, len(parts), 2)]
    chunks, buf = [], ""
    for s in sents:
        if len(buf) + len(s) <= target_max:
            buf += " " + s
        elif len(buf) >= target_min:
            chunks.append(buf.strip()); buf = s
        else:
            buf += " " + s
    if buf.strip(): chunks.append(buf.strip())
    return [(f"ch_{i:05d}", c) for i, c in enumerate(chunks)]

def normalize_voice(input_path, output_path):
    subprocess.run(f'ffmpeg -y -i "{input_path}" -ac 1 -ar 16000 -vn "{output_path}"', shell=True, check=True)

def deepgram_tts(text, out_path):
    url = "https://api.deepgram.com/v1/speak"
    headers = {"Authorization": f"Token {DEEPGRAM_API_KEY}", "Content-Type": "application/json"}
    params = {"model": DG_MODEL, "encoding": "mp3", "bit_rate": 48000}
    r = requests.post(url, headers=headers, params=params, json={"text": text}, stream=True)
    if r.status_code != 200:
        raise RuntimeError(f"Deepgram failed: {r.status_code} {r.text}")
    with open(out_path, "wb") as f:
        for chunk in r.iter_content(8192): f.write(chunk)

def generate_tts_chunks(chunks, max_chunks=2):
    index = []
    for i, (cid, text) in enumerate(chunks[:max_chunks]):
        out_mp3 = AUDIO_DIR / f"{cid}.mp3"
        print(f"üïê Deepgram chunk {i+1}/{max_chunks}: {cid} ({len(text)} chars)")
        deepgram_tts(text, out_mp3)
        index.append({"chunk_id": cid, "mp3": str(out_mp3)})
    return index

def concat_mp3(index, out_mp3=OUT_DIR/"audiobook.mp3"):
    album = AudioSegment.silent(duration=0)
    for i in index:
        seg = AudioSegment.from_file(i["mp3"])
        album += seg + AudioSegment.silent(duration=500)
    album.export(out_mp3, format="mp3", bitrate="192k")
    return out_mp3

def clone_with_openvoice(audio_path, voice_path, output_path):
    norm_path = OUT_DIR / "voice_sample_16k.wav"
    normalize_voice(voice_path, norm_path)
    device = "cuda" if os.path.exists("/proc/driver/nvidia/version") else "cpu"
    result = subprocess.run(
        f'python -m openvoice_cli single -i "{audio_path}" -r "{norm_path}" -o "{output_path}" -d {device}',
        shell=True, capture_output=True, text=True
    )
    if result.returncode != 0:
        raise RuntimeError(f"OpenVoice failed: {result.stderr}")

# === Main Logic ===
def full_pipeline(pdf, voice_sample):
    log = []
    try:
        log.append("üì• Validating uploaded files ‚Ä¶")
        pdf_path = Path(pdf.name)
        voice_path = Path(voice_sample.name)

        if pdf_path.parent != IN_DIR:
            shutil.copy(pdf_path, IN_DIR / pdf_path.name)
            pdf_path = IN_DIR / pdf_path.name
        if voice_path.parent != IN_DIR:
            shutil.copy(voice_path, IN_DIR / voice_path.name)
            voice_path = IN_DIR / voice_path.name

        log.append("üîç Checking if PDF is scanned ‚Ä¶")
        if is_scanned_pdf(pdf_path):
            ocred_path = OUT_DIR / f"{pdf_path.stem}.ocr.pdf"
            log.append("üß† Running OCR ‚Ä¶")
            ocr_to_searchable_pdf(pdf_path, ocred_path)
            text = extract_text(ocred_path)
        else:
            log.append("‚úÖ Searchable PDF ‚Üí extracting text ‚Ä¶")
            text = extract_text(pdf_path)

        text = clean_text(text)[:2000]
        log.append(f"üìù Extracted {len(text):,} characters.")
        chunks = chunk_text(text)
        log.append(f"‚úÇÔ∏è Split into {len(chunks)} chunks.")

        if not chunks:
            return ["‚ùå Error: No valid text chunks extracted from PDF."], None

        log.append("üó£Ô∏è Generating Deepgram audio chunks ‚Ä¶")
        index = generate_tts_chunks(chunks)

        log.append("üéß Concatenating audio chunks ‚Ä¶")
        final_mp3 = concat_mp3(index)

        final_cloned = OUT_DIR / "audiobook_cloned.mp3"
        log.append("üß¨ Cloning voice with OpenVoice ‚Ä¶")
        clone_with_openvoice(final_mp3, voice_path, final_cloned)

        log.append("‚úÖ Done! Final audiobook is ready üéâ")
        return log, str(final_cloned)

    except Exception as e:
        log.append(f"‚ùå Error: {str(e)}")
        return log, None

# === Launch Gradio App ===
with gr.Blocks(theme=gr.themes.Monochrome()) as app:
    gr.Markdown("# üìò PDF to Your Voice", elem_id="title")
    with gr.Row():
        pdf = gr.File(label="Upload PDF")
        voice = gr.File(label="Upload Voice Sample")
    btn = gr.Button("üéôÔ∏è Generate Audiobook in Your Voice")
    output_logs = gr.Textbox(label="Logs", lines=15)
    output_audio = gr.Audio(label="Final Audiobook (Cloned Voice)", type="filepath", interactive=False)

    def run_pipeline_with_ui(pdf_file, voice_file):
        logs, audio_path = full_pipeline(pdf_file, voice_file)
        return "\\n".join(logs), audio_path

    btn.click(fn=run_pipeline_with_ui, inputs=[pdf, voice], outputs=[output_logs, output_audio])

app.launch(share=True)

with open("/mnt/data/final_pdf_to_voice_app.py", "w") as f:
    f.write(code)